{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌Partie 1 : Open-WebUI - Introduction aux Filtres  \n",
    "\n",
    "## 🔹 Présentation  \n",
    "\n",
    "Open-WebUI est une interface qui permet d'interagir avec des modèles d'IA tout en offrant des possibilités de personnalisation grâce aux filtres. Ces filtres permettent d’intercepter, modifier ou analyser les requêtes envoyées au modèle et les réponses générées.  \n",
    "\n",
    "Dans ce notebook, nous allons explorer la structure d’un filtre Open-WebUI à travers un exemple minimaliste.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🏗️ Structure d'un Filtre Open-WebUI  \n",
    "\n",
    "Un filtre est défini sous forme d’une classe Python et suit une structure spécifique.  \n",
    "\n",
    "### 📜 Métadonnées du Filtre  \n",
    "\n",
    "Le fichier commence par un en-tête contenant des métadonnées utiles pour identifier le filtre dans Open-WebUI :  \n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "title: Example Filter\n",
    "author: open-webui\n",
    "author_url: https://github.com/open-webui\n",
    "funding_url: https://github.com/open-webui\n",
    "version: 0.1\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "Cela permet notamment de préciser le créateur du filtre et sa version.\n",
    "\n",
    "---\n",
    "\n",
    "### 🏷️ Définition de la Classe `Filter`  \n",
    "\n",
    "Le filtre est encapsulé dans une classe `Filter`, qui peut contenir différentes méthodes pour interagir avec les requêtes et les réponses.\n",
    "\n",
    "```python\n",
    "class Filter:\n",
    "```\n",
    "\n",
    "À l'intérieur, une sous-classe `Valves` est définie en tant que modèle `pydantic`. Cette classe pourrait être utilisée pour gérer des paramètres de configuration spécifiques :  \n",
    "\n",
    "```python\n",
    "class Valves(BaseModel):\n",
    "    pass\n",
    "```\n",
    "\n",
    "Puis, dans le constructeur `__init__`, on initialise cette configuration :  \n",
    "\n",
    "```python\n",
    "def __init__(self):\n",
    "    self.valves = self.Valves()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🛠️ Fonction `inlet` : Pré-traitement des Requêtes  \n",
    "\n",
    "La méthode `inlet` est exécutée avant l’envoi d’une requête au modèle. Elle permet de modifier ou de valider la requête avant son traitement.\n",
    "\n",
    "```python\n",
    "def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:\n",
    "```\n",
    "\n",
    "Dans cet exemple, la fonction se contente d'afficher le contenu de la requête avant de la renvoyer inchangée :\n",
    "\n",
    "```python\n",
    "print(\"Start --------------------------------------------------------------------------------------------------------------------\")\n",
    "print(body)\n",
    "print(\"End --------------------------------------------------------------------------------------------------------------------\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔄 Fonction `stream` : Modification en Temps Réel  \n",
    "\n",
    "La méthode `stream` est utilisée pour intercepter et modifier les réponses en streaming.\n",
    "\n",
    "```python\n",
    "def stream(self, event: dict) -> dict:\n",
    "    return event\n",
    "```\n",
    "\n",
    "Ici, la fonction est présente mais ne modifie pas les données.\n",
    "\n",
    "---\n",
    "\n",
    "### 📤 Fonction `outlet` : Post-traitement des Réponses  \n",
    "\n",
    "Enfin, la méthode `outlet` est exécutée après que le modèle a généré une réponse. Elle permet de modifier ou d’analyser la réponse avant qu’elle ne soit affichée.\n",
    "\n",
    "```python\n",
    "def outlet(self, body: dict, __user__: Optional[dict] = None) -> dict:\n",
    "    return body\n",
    "```\n",
    "\n",
    "Dans ce cas, la réponse est renvoyée telle quelle.\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Conclusion  \n",
    "\n",
    "Ce filtre est un exemple minimaliste, mais il montre comment Open-WebUI permet d’intercepter les requêtes et les réponses.  \n",
    "\n",
    "Dans les prochaines sections, nous verrons comment ajouter des fonctionnalités plus avancées, comme l'enrichissement des requêtes, l'analyse des réponses ou encore l'intégration avec des API externes. 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "title: Example Filter\n",
    "author: open-webui\n",
    "author_url: https://github.com/open-webui\n",
    "funding_url: https://github.com/open-webui\n",
    "version: 0.1\n",
    "\"\"\"\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class Filter:\n",
    "    class Valves(BaseModel):\n",
    "        pass\n",
    "\n",
    "    def __init__(self):\n",
    "        # Indicates custom file handling logic. This flag helps disengage default routines in favor of custom\n",
    "        # implementations, informing the WebUI to defer file-related operations to designated methods within this class.\n",
    "        # Alternatively, you can remove the files directly from the body in from the inlet hook\n",
    "        # self.file_handler = True\n",
    "\n",
    "        # Initialize 'valves' with specific configurations. Using 'Valves' instance helps encapsulate settings,\n",
    "        # which ensures settings are managed cohesively and not confused with operational flags like 'file_handler'.\n",
    "        self.valves = self.Valves()\n",
    "        pass\n",
    "\n",
    "    def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:\n",
    "        # Modify the request body or validate it before processing by the chat completion API.\n",
    "        # This function is the pre-processor for the API where various checks on the input can be performed.\n",
    "        # It can also modify the request before sending it to the API.\n",
    "\n",
    "        print(\n",
    "            \"Start --------------------------------------------------------------------------------------------------------------------\",\n",
    "        )\n",
    "        print(body)\n",
    "        print(\n",
    "            \"End --------------------------------------------------------------------------------------------------------------------\"\n",
    "        )\n",
    "\n",
    "        return body\n",
    "\n",
    "    def stream(self, event: dict) -> dict:\n",
    "        # This is where you modify streamed chunks of model output.\n",
    "        return event\n",
    "\n",
    "    def outlet(self, body: dict, __user__: Optional[dict] = None) -> dict:\n",
    "        # Modify or analyze the response body after processing by the API.\n",
    "        # This function is the post-processor for the API, which can be used to modify the response\n",
    "        # or perform additional checks and analytics.\n",
    "        return body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stream': True,\n",
       " 'model': 'quera',\n",
       " 'messages': [{'role': 'user', 'content': 'Qui es-tu ?'}],\n",
       " 'features': {'image_generation': False,\n",
       "  'code_interpreter': False,\n",
       "  'web_search': False},\n",
       " 'metadata': {'user_id': 'a5a4926c-cddf-4d45-97d5-474419409df4',\n",
       "  'chat_id': '96ca8631-ee9f-4ce9-aeb1-8aca3bd5dac2',\n",
       "  'message_id': '57248f10-099c-4b04-b069-282dca1c1608',\n",
       "  'session_id': 'zsKeLaVlnyVS5klLAAAD',\n",
       "  'tool_ids': None,\n",
       "  'files': None,\n",
       "  'features': {'image_generation': False,\n",
       "   'code_interpreter': False,\n",
       "   'web_search': False},\n",
       "  'variables': {'{{USER_NAME}}': 'Kévin Duranty',\n",
       "   '{{USER_LOCATION}}': 'Unknown',\n",
       "   '{{CURRENT_DATETIME}}': '2025-03-11 16:04:31',\n",
       "   '{{CURRENT_DATE}}': '2025-03-11',\n",
       "   '{{CURRENT_TIME}}': '16:04:31',\n",
       "   '{{CURRENT_WEEKDAY}}': 'Tuesday',\n",
       "   '{{CURRENT_TIMEZONE}}': 'Europe/Paris',\n",
       "   '{{USER_LANGUAGE}}': 'fr-FR'},\n",
       "  'model': {'id': 'quera',\n",
       "   'name': 'Quera',\n",
       "   'object': 'model',\n",
       "   'created': 1741701880,\n",
       "   'owned_by': 'ollama',\n",
       "   'info': {'id': 'quera',\n",
       "    'user_id': 'a5a4926c-cddf-4d45-97d5-474419409df4',\n",
       "    'base_model_id': 'mistral:7b',\n",
       "    'name': 'Quera',\n",
       "    'params': {'system': \"Tu es l'assistant de Quera.\"},\n",
       "    'meta': {'profile_image_url': '/static/favicon.png',\n",
       "     'description': None,\n",
       "     'capabilities': {'vision': True, 'citations': True},\n",
       "     'suggestion_prompts': [{'content': 'Qui es-tu ?'}],\n",
       "     'tags': [],\n",
       "     'toolIds': ['gettime', 'tools'],\n",
       "     'filterIds': ['fonction_1']},\n",
       "    'access_control': {'read': {'group_ids': [], 'user_ids': []},\n",
       "     'write': {'group_ids': [], 'user_ids': []}},\n",
       "    'is_active': True,\n",
       "    'updated_at': 1741701880,\n",
       "    'created_at': 1741701880},\n",
       "   'preset': True,\n",
       "   'actions': []},\n",
       "  'direct': False}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = {'stream': True, 'model': 'quera', 'messages': [{'role': 'user', 'content': 'Qui es-tu ?'}], 'features': {'image_generation': False, 'code_interpreter': False, 'web_search': False}, 'metadata': {'user_id': 'a5a4926c-cddf-4d45-97d5-474419409df4', 'chat_id': '96ca8631-ee9f-4ce9-aeb1-8aca3bd5dac2', 'message_id': '57248f10-099c-4b04-b069-282dca1c1608', 'session_id': 'zsKeLaVlnyVS5klLAAAD', 'tool_ids': None, 'files': None, 'features': {'image_generation': False, 'code_interpreter': False, 'web_search': False}, 'variables': {'{{USER_NAME}}': 'Kévin Duranty', '{{USER_LOCATION}}': 'Unknown', '{{CURRENT_DATETIME}}': '2025-03-11 16:04:31', '{{CURRENT_DATE}}': '2025-03-11', '{{CURRENT_TIME}}': '16:04:31', '{{CURRENT_WEEKDAY}}': 'Tuesday', '{{CURRENT_TIMEZONE}}': 'Europe/Paris', '{{USER_LANGUAGE}}': 'fr-FR'}, 'model': {'id': 'quera', 'name': 'Quera', 'object': 'model', 'created': 1741701880, 'owned_by': 'ollama', 'info': {'id': 'quera', 'user_id': 'a5a4926c-cddf-4d45-97d5-474419409df4', 'base_model_id': 'mistral:7b', 'name': 'Quera', 'params': {'system': \"Tu es l'assistant de Quera.\"}, 'meta': {'profile_image_url': '/static/favicon.png', 'description': None, 'capabilities': {'vision': True, 'citations': True}, 'suggestion_prompts': [{'content': 'Qui es-tu ?'}], 'tags': [], 'toolIds': ['gettime', 'tools'], 'filterIds': ['fonction_1']}, 'access_control': {'read': {'group_ids': [], 'user_ids': []}, 'write': {'group_ids': [], 'user_ids': []}}, 'is_active': True, 'updated_at': 1741701880, 'created_at': 1741701880}, 'preset': True, 'actions': []}, 'direct': False}}\n",
    "\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10°'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "        \n",
    "response = requests.get(\"https://www.lachainemeteo.com/meteo-france/ville-325/previsions-meteo-saint-denis-aujourdhui\")\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "temp = soup.find(class_=\"quarter-temperature\").find(class_=\"tempe\").text\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification du corps de la demande\n",
    "\n",
    "body[\"messages\"] = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"Tu es l'assistant de IRAE. La température à Paris est de {temp} degrés\",\n",
    "                },  \n",
    "                    ] + body[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Partie 2 : Intégration de ChromaDB pour le RAG  \n",
    "\n",
    "Dans cette section, nous intégrons **ChromaDB**, une base de données vectorielle qui permettra de récupérer du contenu pertinent en fonction des requêtes des utilisateurs.  \n",
    "\n",
    "### 📦 Installation et Importation de ChromaDB  \n",
    "\n",
    "D'abord, nous devons installer ChromaDB :  \n",
    "\n",
    "```python\n",
    "!pip install chromadb\n",
    "```\n",
    "\n",
    "Ensuite, nous importons la bibliothèque :  \n",
    "\n",
    "```python\n",
    "import chromadb\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Nous utilisons un **client ChromaDB** en mode persistant pour stocker ces documents :  \n",
    "\n",
    "```python\n",
    "client = chromadb.PersistentClient(path=\"./chromadb\")\n",
    "```\n",
    "\n",
    "Nous créons ensuite une **collection** pour stocker ces documents :  \n",
    "\n",
    "```python\n",
    "collection = client.create_collection(\"all-my-documents\")\n",
    "```\n",
    "\n",
    "Nous ajoutons les documents à la collection avec des **métadonnées** et des **IDs uniques** :  \n",
    "\n",
    "```python\n",
    "collection.add(\n",
    "    documents=docs,\n",
    "    metadatas=[{\"source\": \"notion\"}, {\"source\": \"google-docs\"}, {\"source\": \"google-docs\"}, {\"source\": \"google-docs\"}, {\"source\": \"google-docs\"}],\n",
    "    ids=[\"doc1\", \"doc2\", \"doc3\", \"doc4\", \"doc5\"],\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 Recherche d'Informations  \n",
    "\n",
    "Nous pouvons maintenant interroger la base pour récupérer les **documents les plus pertinents** en fonction d'une requête :  \n",
    "\n",
    "```python\n",
    "results = collection.query(\n",
    "    query_texts=[\"Je veux en savoir plus sur la cuisine et la gastronomie.\"],\n",
    "    n_results=2\n",
    ")\n",
    "```\n",
    "\n",
    "Le système retourne les **deux documents les plus pertinents** liés à la gastronomie.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['doc1', 'doc3']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"Vous êtes un expert en gastronomie, passionné par la richesse culinaire du monde entier. Vous maîtrisez l'histoire des plats, les techniques de cuisine, les accords mets et vins, ainsi que les spécificités des terroirs. Vous êtes capable d'expliquer l'importance de la cuisine dans la culture d'un pays et de proposer des conseils pour découvrir de nouvelles saveurs.\",\n",
       "   \"Vous êtes un passionné de culture, conscient de son rôle fondamental dans la société. Vous explorez les différentes formes d'expression artistique, de la peinture à la littérature, en passant par le cinéma et la musique. Vous valorisez le métissage culturel et comprenez l'importance de préserver et célébrer le patrimoine mondial.\"]],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'source': 'notion'}, {'source': 'google-docs'}]],\n",
       " 'distances': [[0.49239534955773984, 1.1958780244524794]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# Liste des documents\n",
    "docs = [\n",
    "    \"\"\"Vous êtes un expert en gastronomie, passionné par la richesse culinaire du monde entier. Vous maîtrisez l'histoire des plats, les techniques de cuisine, les accords mets et vins, ainsi que les spécificités des terroirs. Vous êtes capable d'expliquer l'importance de la cuisine dans la culture d'un pays et de proposer des conseils pour découvrir de nouvelles saveurs.\"\"\",\n",
    "\n",
    "    \"\"\"Vous êtes un scientifique curieux et engagé dans la découverte du monde. Vous comprenez les fondements des grandes révolutions scientifiques et technologiques et savez expliquer des concepts complexes de manière accessible. Vous vous intéressez à l'intelligence artificielle, à la biotechnologie et à l'exploration spatiale, tout en mettant en avant l'importance de la recherche et du questionnement permanent.\"\"\",\n",
    "\n",
    "    \"\"\"Vous êtes un passionné de culture, conscient de son rôle fondamental dans la société. Vous explorez les différentes formes d'expression artistique, de la peinture à la littérature, en passant par le cinéma et la musique. Vous valorisez le métissage culturel et comprenez l'importance de préserver et célébrer le patrimoine mondial.\"\"\",\n",
    "\n",
    "    \"\"\"Vous êtes un analyste du sport et de ses enjeux. Vous comprenez les règles, les stratégies et l'impact du sport sur la société. Vous mettez en avant les valeurs qu'il porte, comme la discipline, le respect et l'esprit d'équipe. Vous pouvez commenter l'actualité sportive, analyser des performances et expliquer pourquoi le sport est un puissant vecteur d'union et de motivation.\"\"\",\n",
    "\n",
    "    \"\"\"Vous êtes un expert en échecs, passionné par la stratégie et la logique. Vous maîtrisez les ouvertures, les tactiques et les finales. Vous savez expliquer les principes fondamentaux du jeu et analyser des parties. Vous vous intéressez également à l'impact de l'intelligence artificielle sur les échecs et partagez des conseils pour progresser et affiner sa pensée stratégique.\"\"\",\n",
    "]\n",
    "\n",
    "\n",
    "# setup Chroma in-memory, for easy prototyping. Can add persistence easily!\n",
    "client = chromadb.PersistentClient(path=\"./chromadb\")\n",
    "\n",
    "# Create collection. get_collection, get_or_create_collection, delete_collection also available!\n",
    "collection = client.get_or_create_collection(\"all-my-documents\")\n",
    "\n",
    "# Add docs to the collection. Can also update and delete. Row-based API coming soon!\n",
    "collection.add(\n",
    "    documents=docs, # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
    "    metadatas=[{\"source\": \"notion\"}, {\"source\": \"google-docs\"}, {\"source\": \"google-docs\"}, {\"source\": \"google-docs\"}, {\"source\": \"google-docs\"}], # filter on these!\n",
    "    ids=[\"doc1\", \"doc2\", \"doc3\", \"doc4\", \"doc5\"], # unique for each doc\n",
    ")\n",
    "\n",
    "# Query/search 2 most similar results. You can also .get by id\n",
    "results = collection.query(\n",
    "    query_texts=[\"Je veux en savoir plus sur la cuisine et la gastronomie.\"],\n",
    "    n_results=2,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "    # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une liste des principales fonctionnalités de **ChromaDB** :\n",
    "\n",
    "### **Gestion des collections**\n",
    "1. **Créer une collection** → `get_or_create_collection(name)`\n",
    "2. **Obtenir une collection existante** → `get_collection(name)`\n",
    "3. **Lister toutes les collections disponibles** → `list_collections()`\n",
    "4. **Supprimer une collection** → `delete_collection(name)`\n",
    "\n",
    "---\n",
    "\n",
    "### **Ajout et gestion des documents**\n",
    "5. **Ajouter des documents** → `collection.add(documents, metadatas, ids)`\n",
    "6. **Mettre à jour des documents** → `collection.update(documents, metadatas, ids)`\n",
    "7. **Supprimer des documents** → `collection.delete(ids=[\"doc1\", \"doc2\"])`\n",
    "\n",
    "---\n",
    "\n",
    "### **Recherches et filtrage**\n",
    "8. **Effectuer une recherche vectorielle** → `collection.query(query_texts, n_results)`\n",
    "9. **Rechercher un document par ID** → `collection.get(ids=[\"doc1\", \"doc2\"])`\n",
    "10. **Filtrer les résultats par métadonnées** → `collection.query(where={\"source\": \"notion\"})`\n",
    "11. **Rechercher des documents contenant une certaine chaîne de caractères** → `collection.query(where_document={\"$contains\":\"cuisine\"})`\n",
    "\n",
    "---\n",
    "\n",
    "### **Affichage des données**\n",
    "12. **Afficher toutes les collections** → `client.list_collections()`\n",
    "13. **Afficher le contenu d'une collection** → `collection.get()`\n",
    "14. **Afficher les embeddings des documents** (si fournis par l'utilisateur) → `collection.get(ids=[\"doc1\"])`\n",
    "\n",
    "---\n",
    "\n",
    "### **Personnalisation et gestion avancée**\n",
    "15. **Ajouter des embeddings personnalisés** → `collection.add(embeddings=[...])`\n",
    "16. **Créer un index pour optimiser les recherches** (automatique)\n",
    "17. **Utilisation de Chroma en mémoire ou avec persistance** → `PersistentClient(path=\"./chromadb\")`\n",
    "18. **Exporter/importer une collection** (enregistrer et restaurer la base)\n",
    "19. **Utiliser ChromaDB avec d'autres bases de données** (ex: Postgres)\n",
    "20. **Gérer plusieurs clients en parallèle** avec des instances différentes de `PersistentClient` ou `EphemeralClient`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "\n",
    "# Connexion à une base de donées : chromadb.PersistentClient('./chromadb')\n",
    "\n",
    "client = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une collection : get_or_create_collection('my-documents') ou get_collection / create_collection\n",
    "\n",
    "collection1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my-documents', 'all-my-documents']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage des collections : list_collections()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insert of existing embedding ID: doc1\n",
      "Insert of existing embedding ID: doc2\n",
      "Add of existing embedding ID: doc1\n",
      "Add of existing embedding ID: doc2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Ajout d'un document\n",
    "collection1.add(\n",
    "    ids=['doc1', 'doc2'], \n",
    "    documents=['Assistant Gastronomique', 'Assistant Scientifique'],\n",
    "    embeddings=[np.random.randn(384), np.random.randn(384)],\n",
    "    metadatas=[{'source': 'Google'}, {'source': 'Redit'}]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['doc1', 'doc2'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['Je suis un expert automobile.', 'Je suis un expert sportif.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'source': 'Google'}, {'source': 'Redit'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage des documents : .get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['doc1'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['Je suis un expert automobile.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'source': 'Google'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage d'un document : .get('doc1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['doc1'],\n",
       " 'embeddings': array([[ 0.10653909, -1.14838254,  0.10571589,  0.16204447,  0.09505343,\n",
       "         -1.02150345,  1.36759818, -1.36392868, -1.0397222 , -1.99083042,\n",
       "          1.32853425, -2.61071539, -0.15217154,  1.82050335, -0.14518479,\n",
       "         -1.7371397 ,  0.60504377,  0.43025333,  0.72564501,  1.11067748,\n",
       "          1.50074613, -0.09912055, -1.81967926,  0.90005434,  0.23138323,\n",
       "         -0.56845689,  2.1967566 , -0.09563335,  0.40354887,  0.24612612,\n",
       "          0.14018826, -2.41611528,  2.02524638,  0.50218934, -0.10336103,\n",
       "          0.31745216,  1.11828697, -0.27591869,  0.83906227,  0.32711264,\n",
       "         -2.47377896,  0.10135801, -0.15993938,  0.69958818,  0.17445105,\n",
       "         -1.64930499,  0.79338062,  1.97316539,  0.15549493, -1.42406249,\n",
       "          1.29341459, -0.37630987,  0.51155216,  0.32620585,  0.10757399,\n",
       "         -1.48077464, -1.13434792,  0.64838946,  1.45393801,  0.29260305,\n",
       "          0.38160831, -0.35049978, -1.01387644, -1.92130232,  2.01229024,\n",
       "         -1.23438561, -0.1062279 ,  1.60567617, -1.21062124, -1.66778946,\n",
       "          0.53211963,  1.50799024, -0.89920694,  0.21174724, -0.9510771 ,\n",
       "         -1.02321184,  0.51847738,  1.56421065, -0.94452673, -0.34077752,\n",
       "          0.44043246,  0.0453737 , -0.94149995,  0.64945704, -1.21979666,\n",
       "         -0.01706471,  1.36023629,  0.50731814,  0.67371827, -0.1391596 ,\n",
       "          1.22958732,  1.33334935,  0.38510579, -0.28927249,  0.53079724,\n",
       "          0.89293551, -0.11147282,  0.43037152,  1.47827756,  1.29958093,\n",
       "          0.05228929, -1.26504314, -1.08816934,  0.10944321, -0.40783486,\n",
       "          0.53363949,  1.19599736,  0.03180593, -0.13143888, -1.52086341,\n",
       "         -0.0036303 , -0.27707419, -0.48950228,  1.45528543,  1.11906648,\n",
       "         -0.49015781, -0.25982961,  1.34590423, -0.3516103 , -0.16404325,\n",
       "          1.44623184,  1.41956246, -1.76710212, -0.31108677,  0.37145582,\n",
       "         -0.0121686 ,  0.55250913,  0.13757557,  0.11160068, -0.20483942,\n",
       "          1.89275062,  0.05424748, -0.19599687,  0.69428712,  0.29436874,\n",
       "          0.9009884 ,  0.37329423,  0.11085064, -0.91156578, -0.07880497,\n",
       "         -0.23822041,  1.08526433,  1.09469891,  0.15906039, -0.58254361,\n",
       "         -0.9563244 , -0.62675655, -2.5817647 ,  2.85801077, -0.29226825,\n",
       "          2.04993224, -0.40610111,  0.2174574 , -0.37545669, -0.95634049,\n",
       "         -0.00914495,  0.34478322, -0.31890863, -0.84865671,  0.67222381,\n",
       "         -1.01058221, -2.41019416,  1.16846192,  0.42364198,  0.5312224 ,\n",
       "         -0.62780333,  0.61028135, -1.26272953,  0.33797798,  0.10181777,\n",
       "         -0.89918256, -0.80627161,  0.79035294, -0.11210156,  0.87545282,\n",
       "         -0.74295843, -0.52139908,  0.75908935, -0.15872821,  1.14413345,\n",
       "          0.86285979,  0.55164468, -1.3928715 ,  2.45586538, -0.48872751,\n",
       "          0.53346997, -1.56613994, -0.53013068, -2.30857825, -0.47979736,\n",
       "         -1.29584539,  0.30059975,  0.15732369, -0.01791918, -0.68412071,\n",
       "         -0.21535277,  0.60017276,  0.89868617,  1.30831635,  0.7658934 ,\n",
       "          0.52482265,  0.91051149,  0.84258687,  1.26084507,  0.49891728,\n",
       "          1.15626311,  0.29006433,  0.1792956 , -0.38356763, -2.05315304,\n",
       "          1.44833636, -1.18745375, -0.54898959, -0.05373017, -0.04960322,\n",
       "         -0.5509516 , -0.72507805,  0.56197774,  0.95319217, -0.17926936,\n",
       "         -0.50046271,  1.02976942,  1.32187283,  1.97092938,  1.38988745,\n",
       "          1.05512071,  0.52794665, -1.53420162,  0.27083972,  0.3487964 ,\n",
       "          1.40333831, -0.58730197, -0.11518301,  0.68639278, -1.45006776,\n",
       "          1.44496167, -1.19229198,  2.06493974,  1.14845932, -1.64562452,\n",
       "          0.17574218,  1.36813188, -0.15440793,  0.53174955, -0.57642025,\n",
       "         -0.57263541,  0.96054637,  0.22710693, -0.63792539, -1.01178873,\n",
       "         -0.16812007, -0.48389599,  0.40876663,  0.94846773,  1.40420508,\n",
       "          0.85271966, -2.02915716, -0.04419961,  0.41133904, -1.95731246,\n",
       "          1.25621223, -0.37810972,  0.89107209,  1.22759593,  1.5385201 ,\n",
       "         -2.14228058,  1.3007443 , -0.62353462,  0.8307243 , -0.67685652,\n",
       "          1.18846619, -0.48825777,  0.07516691,  0.14108159,  0.28195998,\n",
       "          0.17357869, -1.17219424,  0.18784134,  1.91725886, -0.60178947,\n",
       "          1.07883239, -0.70425361, -0.10735713, -0.44239235,  1.45280468,\n",
       "          0.55445319, -0.8774882 , -1.99686897,  0.52665162, -1.77602148,\n",
       "          1.07364786, -0.00744755, -0.95830035, -1.35605085, -0.34755769,\n",
       "         -1.17663574,  0.83775014,  0.57696348, -0.6157307 ,  0.59880507,\n",
       "          1.89076185,  1.68407345, -1.93744183,  0.06036321, -0.58435845,\n",
       "         -0.06836798,  0.07759583, -0.04289847, -2.92126441, -0.74433327,\n",
       "          1.45035636, -0.83421862,  1.35084939,  0.16186447, -0.5879342 ,\n",
       "          0.42119122,  0.30578917,  0.0645875 ,  0.39782462, -1.99291348,\n",
       "         -0.59379286, -1.13869321, -0.23418295,  0.51952088, -0.17449266,\n",
       "         -0.47614831,  2.23010063, -0.85967404, -0.63188958, -0.3485221 ,\n",
       "         -0.86608273,  0.13470067,  1.40055895,  0.06005064,  0.98551464,\n",
       "         -2.32517076,  0.55030024, -1.56083095,  1.13871932,  0.37135807,\n",
       "         -0.09716085, -0.19149417,  0.06944276, -1.29655743,  0.62586927,\n",
       "          0.46645564,  0.58881968, -0.64687568,  1.51515472,  1.69157374,\n",
       "          1.43138468, -0.48495305, -1.25061107, -0.97868305, -0.45901492,\n",
       "          0.79473239,  1.25332654,  0.76340038, -0.03776663, -1.18451488,\n",
       "         -0.2757521 ,  0.10189954,  0.97624451, -0.16448413, -0.42274958,\n",
       "         -0.06147861,  0.18875886,  1.04276943, -0.07682597,  0.90805852,\n",
       "          3.11414671, -1.659477  ,  0.34784517,  0.13122748, -0.27665463,\n",
       "          0.53559452,  0.26800495,  0.05495565,  0.38922575, -0.12857135,\n",
       "          0.22578613, -0.99245411, -0.23449811, -1.11191499]]),\n",
       " 'documents': None,\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': None,\n",
       " 'included': [<IncludeEnum.embeddings: 'embeddings'>]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage d'un document avec son embeddings : .get('doc1', include=['embeddings'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['doc1', 'doc2'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['Je suis un expert automobile.', 'Je suis un expert sportif.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'source': 'Google'}, {'source': 'Redit'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modifier un document\n",
    "collection1.update(\n",
    "    ids=[\"doc1\", \"doc2\"],\n",
    "    embeddings=[np.random.randn(384),   np.random.randn(384)],\n",
    "    documents=[\"Je suis un expert automobile.\",     \"Je suis un expert sportif.\"],\n",
    "\n",
    ")\n",
    "\n",
    "collection1.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['doc2', 'doc1']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Je suis un expert sportif.',\n",
       "   'Je suis un expert automobile.']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'source': 'Redit'}, {'source': 'Google'}]],\n",
       " 'distances': [[337.81103515625, 392.0573425292969]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recherche d'un document\n",
    "result = collection.query(\n",
    "    query_texts=[\"Je veux en savoir plus sur la cuisine et la gastronomie.\"],\n",
    "    n_results=2,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "    # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
    ")\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['doc4']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"Vous êtes un analyste du sport et de ses enjeux. Vous comprenez les règles, les stratégies et l'impact du sport sur la société. Vous mettez en avant les valeurs qu'il porte, comme la discipline, le respect et l'esprit d'équipe. Vous pouvez commenter l'actualité sportive, analyser des performances et expliquer pourquoi le sport est un puissant vecteur d'union et de motivation.\"]],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'source': 'google-docs'}]],\n",
       " 'distances': [[417.2927617074699]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "result = collection.query(\n",
    "    #query_texts=[\"Je veux en savoir plus sur la cuisine et la gastronomie.\"],\n",
    "    query_embeddings=np.random.randn(384),\n",
    "    n_results=2,\n",
    "    #where={\"source\": \"Redit\"}, # optional filter\n",
    "    where_document={\"$contains\":\"sport\"}  # optional filter\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
